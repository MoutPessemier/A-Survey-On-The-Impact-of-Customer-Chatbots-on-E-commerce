% Encoding: UTF-8
@Comment{jabref-meta: databaseType:bibtex;}
@article{Adamopoulou2020,
	abstract = {This literature review presents the History, Technology, and Applications of Natural Dialog Systems or simply chatbots. It aims to organize critical information that is a necessary background for further research activity in the field of chatbots. More specifically, while giving the historical evolution, from the generative idea to the present day, we point out possible weaknesses of each stage. After we present a complete categorization system, we analyze the two essential implementation technologies, namely, the pattern matching approach and machine learning. Moreover, we compose a general architectural design that gathers critical details, and we highlight crucial issues to take into account before system design. Furthermore, we present chatbots applications and industrial use cases while we point out the risks of using chatbots and suggest ways to mitigate them. Finally, we conclude by stating our view regarding the direction of technology so that chatbots will become really smart.},
	author = {Eleni Adamopoulou and Lefteris Moussiades},
	doi = {10.1016/j.mlwa.2020.100006},
	issn = {26668270},
	journal = {Machine Learning with Applications},
	month = {12},
	pages = {100006},
	publisher = {Elsevier BV},
	title = {Chatbots: History, technology, and applications},
	volume = {2},
	year = {2020},
}
@article{Bansal2018,
	abstract = {The advancement in the development of computer technology has led to the idea of human computer interaction. Research experiments in human computer interaction involves the young age group of people that are educated and technically knowledgeable. This paper focuses on the mental model in Human Computer Interaction. There are various approaches of this review paper and one of them is highlighting current approach, results and the trends in the human computer interaction and the second approach is to find out the research that have been invented a long time before and are currently lagging behind. This paper also focuses on the emotional intelligence of a user to become more user like, fidelity prototyping. The development and design of an automated system that perform such task is still being accomplished.},
	author = {Himanshu Bansal and Rizwan Khan},
	doi = {10.23956/ijarcsse.v8i4.630},
	issn = {22776451},
	issue = {4},
	journal = {International Journal of Advanced Research in Computer Science and Software Engineering},
	month = {4},
	pages = {53},
	publisher = {Advance Academic Publisher},
	title = {A Review Paper on Human Computer Interaction},
	volume = {8},
	year = {2018},
}
@report{Radziwil2021,
	abstract = {Chatbots are one class of intelligent, conversational software agents activated by natural language input (which can be in the form of text, voice, or both). They provide conversational output in response, and if commanded, can sometimes also execute tasks. Although chatbot technologies have existed since the 1960's and have influenced user interface development in games since the early 1980's, chatbots are now easier to train and implement. This is due to plentiful open source code, widely available development platforms, and implementation options via Software as a Service (SaaS). In addition to enhancing customer experiences and supporting learning, chatbots can also be used to engineer social harm-that is, to spread rumors and misinformation, or attack people for posting their thoughts and opinions online. This paper presents a literature review of quality issues and attributes as they relate to the contemporary issue of chatbot development and implementation. Finally, quality assessment approaches are reviewed, and a quality assessment method based on these attributes and the Analytic Hierarchy Process (AHP) is proposed and examined.},
	author = {Nicole Radziwill and Morgan Benton},
	keywords = {Analytic Hierarchy Process (AHP),artificial intelligence,chatbot,intelligent agents,quality attributes,usability},
	title = {Evaluating Quality of Chatbots and Intelligent Conversational Agents},
	url = {http://www.masswerk.at/elizabot/eliza.html},
}
@inproceedings{Maroengsit2019,
	abstract = {Nowadays chatbots have been widely adopted in many industries to automatically answer users' questions and requests via chat interfaces. While it has become much easier to develop a chatbot system, the system itself is a complex system in nature. It is a challenge to evaluate and compare various chatbot systems in terms of effectiveness, efficiency, goal achievability, and the ability to satisfy users. This paper presents a survey, starting from literature review, chatbot architecture, evaluation methods/criteria, and comparison of evaluation methods. Focused on the three subprocesses in the chatbot architecture: text processing, semantic understanding, and response generation. Moreover, the survey is conducted with classification of chatbot evaluation methods and their analysis according to chatbot types and three main evaluation schemes; content evaluation, user satisfaction, and chat function.},
	author = {Wari Maroengsit and Thanarath Piyakulpinyo and Korawat Phonyiam and Suporn Pongnumkul and Pimwadee Chaovalit and Thanaruk Theeramunkong},
	doi = {10.1145/3323771.3323824},
	isbn = {9781450366397},
	issn = {21531633},
	journal = {PervasiveHealth: Pervasive Computing Technologies for Healthcare},
	keywords = {Chatbot Evaluation,Information Systems,Natural Language Processing,Natural Language Understanding},
	pages = {111-119},
	publisher = {ICST},
	title = {A survey on evaluation methods for chatbots},
	volume = {Part F148391},
	year = {2019},
}
@inproceedings{Nuruzzaman2018,
	abstract = {Nowadays it is the era of intelligent machine. With the advancement of artificial intelligent, machine learning and deep learning, machines have started to impersonate as human. Conversational software agents activated by natural language processing is known as chatbot, are an excellent example of such machine. This paper presents a survey on existing chatbots and techniques applied into it. It discusses the similarities, differences and limitations of the existing chatbots. We compared 11 most popular chatbot application systems along with functionalities and technical specifications. Research showed that nearly 75\% of customers have experienced poor customer service and generation of meaningful, long and informative responses remains a challenging task. In the past, methods for developing chatbots have relied on hand-written rules and templates. With the rise of deep learning these models were quickly replaced by end-to-end neural networks. More specifically, Deep Neural Networks is a powerful generative-based model to solve the conversational response generation problems. This paper conducted an in-depth survey of recent literature, examining over 70 publications related to chatbots published in the last 5 years. Based on literature review, this study made a comparison from selected papers according to method adopted. This paper also presented why current chatbot models fails to take into account when generating responses and how this affects the quality conversation.},
	author = {Mohammad Nuruzzaman and Omar Khadeer Hussain},
	doi = {10.1109/ICEBE.2018.00019},
	isbn = {9781538679920},
	journal = {Proceedings - 2018 IEEE 15th International Conference on e-Business Engineering, ICEBE 2018},
	keywords = {Chatbot,Deep learning,Dialogue system,Natural language processing,Neural network},
	month = {12},
	pages = {54-61},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	title = {A Survey on Chatbot Implementation in Customer Service Industry through Deep Neural Networks},
	year = {2018},
}
@report{Verkeyn2018,
	author = {Juan Verkeyn and Herm√®s Meerschmans},
	title = {TOWARDS A BETTER UNDERSTANDING OF SERVICE QUALITY ATTRIBUTES OF A CHATBOT },
	url = {https://libstore.ugent.be/fulltxt/RUG01/002/784/375/RUG01-002784375_2019_0001_AC.pdf},
	year = {2018},
}
@article{Muizzah2021,
	abstract = {A chatbot is an application that is widely used in diverse industries nowadays. The application makes used of human natural language to interact with the user in order to carry out any designated task. It started with an experiment conducted by Alan Turing which was named as Turing Test in the 1950s that has contributed to the evolution of technology into personal intelligence assistance. Siri, Cortana, and other services are the product of the evolution that was created with the aim to induce user satisfaction while completing the desired task. Various features of Chatbot have been introduced to support the functionality and purpose of the application. Availability, functionality, ethics, personality, and appearance of the interfaces are among of the features favored by the end-user. Thus, this paper aims to records all features available and making a summary based on past researches conducted. The outcome will be reflected as a guideline to develop a new improved Chatbot.},
	author = {Nurul Muizzah Johari and Puteri NE Nohuddin},
	doi = {10.34218/IJEET.12.7.2021.012},
	issn = {0976-6553},
	issue = {7},
	journal = {International Journal of Electrical Engineering and Technology (IJEET)},
	keywords = {Artificial Intelligence,Chatbot,Natural Language,Quality Attributes},
	pages = {109-119},
	title = {Quality Attributes for a Good Chatbot: A Literature Review},
	volume = {12},
	year = {2021},
}
@report{ISO9126,
	abstract = {ISO/IEC 9126 is currently one of the most widespread quality standards. In its actual form it embraces both quality models and metrics. Due to its generic nature, some of the concepts presented therein need to be refined before using the standard in a real project. In our paper, we aim at exploring which are the concepts that require being more elaborated before putting the standard to work. Specifically, with respect to the part 1 of the standard we focus on the hierarchical form of the quality entities (i.e., characteristics, subcharacteristics and attributes) that appear in quality models; we propose some criteria to distinguish among subcharacteristics and attributes; we distinguish among derived attributes and basic attributes; and we propose an extension for covering not only technical factors but also managerial and political ones. Concerning the other 3 parts of the standard (one of them currently pending of approval), we distinguish different categorization criteria of metrics (scale, type, objectivity, qualitative/quantitative) and we make explicit the rationale behind their definition with the Goal-Question-Metric approach. As a final contribution, we show the use of UML class diagrams for representing all the concepts of the standard and their relationships, and we highlight the need for having tool support for quality model development and metrics definition.},
	author = {P Botella and X Burgu√©s and J P Carvallo and X Franch and G Grau and J Marco and C Quer},
	title = {ISO/IEC 9126 in practice: what do we need to know?},
}
@article{brandtzaeg2020,
	abstract = {For chatbots to be broadly adopted by users, it is critical that they are experienced as useful and pleasurable. While there is an emerging body of research concerning user uptake and use of chatbots, there is a lack of theoretically grounded studies detailing what constitutes good or poor chatbot user experiences. In this paper, we present findings from a questionnaire study involving more than 200 chatbot users who reported on episodes of chatbot use that they found particularly satisfactory or frustrating. The user reports were analysed with basis in theory on user experience, with particular concern for pragmatic and hedonic attributes. We found that pragmatic attributes such as efficient assistance (positive) and problems with interpretation (negative) were important elements in user reports of satisfactory and frustrating episodes. Hedonic attributes such as entertainment value (positive) and strange and rude responses (negative) were also frequently mentioned. Older participants tended to report on pragmatic attributes more often, whereas younger participants tended to report on hedonic attributes more often. Drawing on the findings, we propose four high-level lessons learnt that may benefit chatbot service providers, and we suggest relevant future research.},
	author = {Asbj√∏rn F√∏lstad and Petter Bae Brandtzaeg},
	doi = {10.1007/s41233-020-00033-2},
	issn = {2366-0139},
	issue = {1},
	journal = {Quality and User Experience},
	month = {12},
	publisher = {Springer Science and Business Media LLC},
	title = {Users' experiences with chatbots: findings from a questionnaire study},
	volume = {5},
	year = {2020},
}
@article{Cohen2016,
	author = {David Cohen and Ian Lane},
	issue = {1},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	month = {2},
	title = {An Oral Exam for Measuring a Dialog System‚Äôs Capabilities},
	volume = {30},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/10060},
	year = {2016},
}
@inproceedings{Eeuwen2017,
	author = {M van Eeuwen},
	title = {Mobile conversational commerce: messenger chatbots as the next interface between businesses and consumers},
	year = {2017},
}
@article{Kuligowska2015,
	author = {Karolina Kuligowska},
	doi = {10.18483/PCBR.22},
	journal = {Professionals Center for Business Research},
	month = {12},
	pages = {1-16},
	title = {Commercial Chatbot: Performance Evaluation, Usability Metrics and Quality Standards of Embodied Conversational Agents},
	volume = {2},
	year = {2015},
}
@report{Candela2018,
	abstract = {This research focuses on investigating Italians consumers' perception and attitude towards chatbots adoption. The Uses and Gratification Theory (UGT), Technology Acceptance Model (TAM) and Diffusion of Innovation theory (DOI) have been combined to build a conceptual framework. Hypothesis have been tested thought a quantitative research such as a questionnaire. The questionnaire was distributed via online channels such as Facebook Groups, Instagram and WhatsApp. The author adopted a statistical analysis to investigate the relationship between consumers' perception and attitude towards chatbots. From the findings the author identified a significant correlation between positive attitude and perception and chatbot adoption. Furthermore, the author discovered that productivity was the main motivation for chatbot adoption. At the end of this paper the author provided some suggestions for companies based on the information collected from this research.},
	author = {Edmondo Candela},
	institution = {Aalborg University},
	title = {Consumers' perception and attitude towards chatbots' adoption. A focus on the Italian market},
	url = {https://projekter.aau.dk/projekter/files/281244069/IM_thesis_EdmondoCandela.pdf},
	year = {2018},
}
@article{Wang2019,
	abstract = {Vendors of mobile communication applications/services (apps) aim at improve their designs to attract and retain users, and thus achieve the critical mass needed to ensure the success of their services. Despite the significant number of prior mobile service studies, few works have examined the effects of inertia and satisfaction on the users‚Äô continuance intention with regard to specific mobile communication apps from a mobile-service-quality perspective. By integrating the mobile service quality framework, inertia, and user satisfaction, this study develops a model for interpreting the development of the continuance intention of users of mobile communication apps. Data collected from 238 users of such apps provided support for the model. The results indicated that interaction quality, environment quality, inertia, and user satisfaction are key determinants of continuance intention, while outcome quality is not. The theoretical and practical implications of this work are discussed.},
	author = {Wei-Tsong Wang and Wei-Ming Ou and Wen-Yin Chen},
	doi = {https://doi.org/10.1016/j.ijinfomgt.2018.10.011},
	issn = {0268-4012},
	journal = {International Journal of Information Management},
	keywords = {Continuance intention,Inertia,Mobile communication applications,Mobile service quality,User satisfaction},
	pages = {178-193},
	title = {The impact of inertia and user satisfaction on the continuance intentions to use mobile communication applications: A mobile service quality perspective},
	volume = {44},
	url = {https://www.sciencedirect.com/science/article/pii/S0268401218304651},
	year = {2019},
}
@thesis{Duijst2017,
	author = {Dani√´lle Duijst},
	doi = {10.13140/RG.2.2.36112.92165},
	month = {7},
	title = {Can we Improve the User Experience of Chatbots with Personalisation?},
	year = {2017},
}
@inproceedings{Morrissey2013,
	abstract = {The aim of this research is to generate measurable evaluation criteria acceptable to chatbot users. Results of two studies are summarised. In the first, fourteen participants were asked to do a critical incident analysis of their transcriptions with an ELIZA-type chatbot. Results were content analysed, and yielded seven overall themes. In the second, these themes were made into statements of an attitude-like nature, and 20 participants chatted with five winning entrants in the 2011 Chatterbox Challenge and five which failed to place. Latent variable analysis reduced the themes to four, resulting in four subscales with strong reliability which discriminated well between the two categories of chatbots. Content analysis of freeform comments led to a proposal of four dimensions along which people judge the naturalness of a conversation with chatbots.},
	author = {Kellie Morrissey and Jurek Kirakowski},
	city = {Berlin, Heidelberg},
	editor = {Masaaki Kurosu},
	isbn = {978-3-642-39330-3},
	journal = {Human-Computer Interaction. Interaction Modalities and Techniques},
	pages = {87-96},
	publisher = {Springer Berlin Heidelberg},
	title = {`Realness' in Chatbots: Establishing Quantifiable Criteria},
	year = {2013},
}
@article{Ashfaq2020,
	abstract = {Chatbots are mainly text-based conversational agents that simulate conversations with users. This study aims to investigate drivers of users‚Äô satisfaction and continuance intention toward chatbot-based customer service. We propose an analytical framework combining the expectation-confirmation model (ECM), information system success (ISS) model, TAM, and the need for interaction with a service employee (NFI-SE). Analysis of data collected from 370 actual chatbot users reveals that information quality (IQ) and service quality (SQ) positively influence consumers‚Äô satisfaction, and that perceived enjoyment (PE), perceived usefulness (PU), and perceived ease of use (PEOU) are significant predictors of continuance intention (CI). The need for interaction with an employee moderates the effects of PEOU and PU on satisfaction. The findings also revealed that satisfaction with chatbot e-service is a strong determinant and predictor of users‚Äô CI toward chatbots. Thus, chatbots should enhance their information and service quality to increase users‚Äô satisfaction. The findings imply that digital technologies services, such as chatbots, could be combined with human service employees to satisfy digital users.},
	author = {Muhammad Ashfaq and Jiang Yun and Shubin Yu and Sandra Maria Correia Loureiro},
	doi = {10.1016/j.tele.2020.101473},
	issn = {07365853},
	journal = {Telematics and Informatics},
	keywords = {Chatbots,Continuance intention,ECM,ISS model,Satisfaction,TAM,The need for interaction},
	month = {11},
	publisher = {Elsevier Ltd},
	title = {I, Chatbot: Modeling the determinants of users‚Äô satisfaction and continuance intention of AI-powered service agents},
	volume = {54},
	year = {2020},
}
@report{Goot2020,
	abstract = {The current qualitative interview study describes the communication journey of customers who wish to contact companies, and their evaluation of chatbot communication within this journey. Interviews were conducted with a sample (N=24) that was varied in terms of gender, age, educational level and household composition. Experiences with nine customer service chatbots were included. The analysis focuses on three stages in the journey: first, customers' prior expectations when contacting a company; second, their experiences during chatbot conversations, and third, their final conclusions about under which conditions customer service chatbots should be implemented, and the consequences of chatbot communication for customers' company perceptions. Implications for research and practice are discussed. 1 Introduction Developments in AI fundamentally alter how companies communicate with their customers [9]. Particularly in customer service, chatbots are increasingly implemented [7, 11, 12]. Customers who need information or who want to complain can type their questions in a dialogue screen (often looking like a chat interface), and receive answers in natural language. The essential characteristic of this type of communication is that, although the answers are automatically generated, the conversation is made to resemble a dialogue between humans [7]. Since this is a novel way of interacting with a company, the question arises how customers experience these conversations, and how this communication affects their company perceptions. The current qualitative interview study aims to shed light on these issues by describing the communication journey of customers who wish to contact companies, and their evaluation of chatbot communication within this journey. The analysis focuses on three stages in the journey: first, customers' prior expectations when contacting a company; second, their experiences during chat-bot conversations, and third, their final conclusions about under which conditions customer service chatbots should be implemented, and the consequences of chatbot communication for customers'company perceptions.},
	author = {Margot J Van Der Goot and Laura Hafkamp and Zo√´ Dankfort},
	keywords = {AI,Chatbots,Company perceptions,Customer service,Qualitative interview study,User experience},
	title = {Customer Service Chatbots: A Qualitative Interview Study into Customers' Communication Journey},
	year = {2020},
}
@article{Brandtzaeg2018,
	author = {Petter Bae Brandtzaeg and Asbj√∏rn F√∏lstad},
	doi = {10.1145/3236669},
	issn = {15583449},
	issue = {5},
	journal = {Interactions},
	month = {9},
	pages = {38-43},
	publisher = {Association for Computing Machinery},
	title = {Chatbots: User changing needs and motivations},
	volume = {25},
	year = {2018},
}
@article{Adam2021,
	abstract = {Communicating with customers through live chat interfaces has become an increasingly popular means to provide real-time customer service in many e-commerce settings. Today, human chat service agents are frequently replaced by conversational software agents or chatbots, which are systems designed to communicate with human users by means of natural language often¬†based on artificial intelligence (AI). Though cost- and time-saving opportunities triggered a widespread implementation of AI-based chatbots, they still frequently fail to meet customer expectations, potentially resulting in users being less inclined to comply with requests made by the chatbot. Drawing on social response and commitment-consistency theory, we empirically examine through a randomized online experiment how verbal anthropomorphic design cues and the foot-in-the-door technique affect user request compliance. Our results demonstrate that both anthropomorphism as well as the need to stay consistent significantly increase the likelihood that users comply with a chatbot‚Äôs request for service feedback. Moreover, the results show that social presence mediates the effect of anthropomorphic design cues on user compliance.},
	author = {Martin Adam and Michael Wessel and Alexander Benlian},
	doi = {10.1007/s12525-020-00414-7},
	issn = {14228890},
	issue = {2},
	journal = {Electronic Markets},
	keywords = {Anthropomorphism,Artificial intelligence,Chatbot,Compliance,Customer service,Social presence},
	month = {6},
	pages = {427-445},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	title = {AI-based chatbots in customer service and their effects on user compliance},
	volume = {31},
	year = {2021},
}
@article{Cheng2021,
	abstract = {Purpose: Artificial intelligence (AI)-based chatbots have brought unprecedented business potential. This study aims to explore consumers' trust and response to a text-based chatbot in e-commerce, involving the moderating effects of task complexity and chatbot identity disclosure. Design/methodology/approach: A survey method with 299 useable responses was conducted in this research. This study adopted the ordinary least squares regression to test the hypotheses. Findings: First, the consumers' perception of both the empathy and friendliness of the chatbot positively impacts their trust in it. Second, task complexity negatively moderates the relationship between friendliness and consumers' trust. Third, disclosure of the text-based chatbot negatively moderates the relationship between empathy and consumers' trust, while it positively moderates the relationship between friendliness and consumers' trust. Fourth, consumers' trust in the chatbot increases their reliance on the chatbot and decreases their resistance to the chatbot in future interactions. Research limitations/implications: Adopting the stimulus‚Äìorganism‚Äìresponse (SOR) framework, this study provides important insights on consumers' perception and response to the text-based chatbot. The findings of this research also make suggestions that can increase consumers' positive responses to text-based chatbots. Originality/value: Extant studies have investigated the effects of automated bots' attributes on consumers' perceptions. However, the boundary conditions of these effects are largely ignored. This research is one of the first attempts to provide a deep understanding of consumers' responses to a chatbot.},
	author = {Xusen Cheng and Ying Bao and Alex Zarifis and Wankun Gong and Jian Mou},
	doi = {10.1108/INTR-08-2020-0460},
	issn = {10662243},
	journal = {Internet Research},
	keywords = {Consumers‚Äô response,Identity disclosure,Task complexity,Text-based chatbot,Trust},
	note = {<br/>},
	publisher = {Emerald Group Holdings Ltd.},
	title = {Exploring consumers' response to text-based chatbots in e-commerce: the moderating role of task complexity and chatbot disclosure},
	year = {2021},
}
@inproceedings{Ischen2020,
	abstract = {Chatbots are increasingly used in a commercial context to make product- or service-related recommendations. By doing so, they collect personal information of the user, similar to other online services. While privacy concerns in an online (website-) context are widely studied, research in the context of chatbot-interaction is lacking. This study investigates the extent to which chatbots with human-like cues influence perceptions of anthropomorphism (i.e., attribution of human-like characteristics), privacy concerns, and consequently, information disclosure, attitudes and recommendation adherence. Findings show that a human-like chatbot leads to more information disclosure, and recommendation adherence mediated by higher perceived anthropomorphism and subsequently, lower privacy concerns in comparison to a machine-like chatbot. This result does not hold in comparison to a website; human-like chatbot and website were perceived as equally high in anthropomorphism. The results show the importance of both mediating concepts in regards to attitudinal and behavioral outcomes when interacting with chatbots.},
	author = {Carolin Ischen and Theo Araujo and Hilde Voorveld and Guda van Noort and Edith Smit},
	doi = {10.1007/978-3-030-39540-7_3},
	isbn = {9783030395391},
	issn = {16113349},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	keywords = {Anthropomorphism,Chatbots,Privacy concerns},
	pages = {34-48},
	publisher = {Springer},
	title = {Privacy Concerns in Chatbot Interactions},
	volume = {11970 LNCS},
	year = {2020},
}
@article{Go2019,
	abstract = {Chatbots are replacing human agents in a number of domains, from online tutoring to customer-service to even cognitive therapy. But, they are often machine-like in their interactions. What can we do to humanize chatbots? Should they necessarily be driven by human operators for them to be considered human? Or, will an anthropomorphic visual cue on the interface and/or a high-level of contingent message exchanges provide humanness to automated chatbots? We explored these questions with a 2 (anthropomorphic visual cues: high vs. low anthropomorphism) √ó 2 (message interactivity: high vs. low message interactivity) √ó 2 (identity cue: chat-bot vs. human) between-subjects experiment (N = 141) in which participants interacted with a chat agent on an e-commerce site about choosing a digital camera to purchase. Our findings show that a high level of message interactivity compensates for the impersonal nature of a chatbot that is low on anthropomorphic visual cues. Moreover, identifying the agent as human raises user expectations for interactivity. Theoretical as well as practical implications of these findings are discussed.},
	author = {Eun Go and S. Shyam Sundar},
	doi = {10.1016/j.chb.2019.01.020},
	issn = {07475632},
	journal = {Computers in Human Behavior},
	keywords = {Anthropomorphic visual cue,Compensation effect,Expectancy violation effect,Identity cue,Message interactivity,Online chat agents},
	month = {8},
	pages = {304-316},
	publisher = {Elsevier Ltd},
	title = {Humanizing chatbots: The effects of visual, identity and conversational cues on humanness perceptions},
	volume = {97},
	year = {2019},
}
@article{Shyam2008,
	author = {S Shyam Sundar},
	doi = {10.1162/dmal.9780262562324.073},
	pages = {73-100},
	publisher = {The MIT Press},
	title = {The MAIN Model: A Heuristic Approach to Understanding Technology Effects on Credibility},
	year = {2008},
}
@article{KANO1984,
	author = {Noriaki KANO and Nobuhiko SERAKU and Fumio TAKAHASHI and Shin-ichi TSUJI},
	doi = {10.20684/quality.14.2_147},
	issue = {2},
	journal = {Journal of The Japanese Society for Quality Control},
	pages = {147-156},
	title = {Attractive Quality and Must-Be Quality},
	volume = {14},
	year = {1984},
}
@article{Gong2007,
	abstract = {Computer-generated anthropomorphic characters are a growing type of communicator that is deployed in digital communication environments. An essential theoretical question is how people identify humanlike but clearly artificial, hence humanoid, entities in comparison to natural human ones. This identity categorization inquiry was approached under the framework of consistency and tested through examining inconsistency effects from mismatching categories. Study 1 (N = 80), incorporating a self-disclosure task, tested participants' responses to a talking-face agent, which varied in four combinations of human versus humanoid faces and voices. In line with the literature on inconsistency, the pairing of a human face with a humanoid voice or a humanoid face with a human voice led to longer processing time in making judgment of the agent and less trust than the pairing of a face and a voice from either the human or the humanoid category. Female users particularly showed negative attitudes toward inconsistently paired talking faces. Study 2 (N = 80), using a task that stressed comprehension demand, replicated the inconsistency effects on judging time and females' negative attitudes but not for comprehension-related outcomes. Voice clarity overshadowed the consistency concern for comprehension-related responses. The overall inconsistency effects suggest that people treat humanoid entities in a different category from natural human ones. ¬© 2007 International Communication Association.},
	author = {Li Gong and Clifford Nass},
	doi = {10.1111/j.1468-2958.2007.00295.x},
	issn = {03603989},
	issue = {2},
	journal = {Human Communication Research},
	month = {4},
	pages = {163-193},
	title = {When a talking-face computer agent is half-human and half-humanoid: Human identity and consistency preference},
	volume = {33},
	year = {2007},
}
@article{Kim2012,
	abstract = {In analyzing the human tendency to treat computers as social actors (CASA), researchers tend to rule out the anthropomorphism explanation because anthropomorphism is understood to be "a sincere, conscious belief" that computers are human and/or deserving of human attributions. But, does anthropomorphism have to be necessarily mindful? Could it not also be a mindless tendency, especially given that most of us have somewhat long associations with our computers and have built human-like bonds with them? We examined these questions empirically by investigating whether the user tendency to treat computers as human beings is conscious (mindful) or non-conscious (mindless). We manipulated two variables (presence/absence of human-like agent and the low/high interactivity) on a health website and experimentally investigated whether they serve as anthropomorphic cues to trigger mindful attributions of human-ness to the website or mindless evaluations of the site in human terms. We found evidence for mindless anthropomorphism, with implications for user judgments of credibility of information on the site. ¬© 2011 Elsevier Ltd. All rights reserved.},
	author = {Youjeong Kim and S. Shyam Sundar},
	doi = {10.1016/j.chb.2011.09.006},
	issn = {07475632},
	issue = {1},
	journal = {Computers in Human Behavior},
	keywords = {Anthropomorphism,Human-like agent,Information credibility,Interactivity,Social presence},
	month = {1},
	pages = {241-250},
	title = {Anthropomorphism of computers: Is it mindful or mindless?},
	volume = {28},
	year = {2012},
}
@article{Nowak2004,
	abstract = {This project examined how information provided in virtual worlds influences social judgment. It specifically tested the influence of anthropomorphism and agency on the level of uncertainty and social judgment, using a between-subjects experimental design. Anthropomorphism had three levels; a high anthropomorphic image, a low anthropomorphic image and no image. Agency had two levels; whether the participants were told they were interacting with a human (avatar condition) or a computer (agent condition). The results showed that the virtual image influenced social judgment. The less anthropomorphic image was perceived to be more credible and likeable than no image, which was more credible and likeable than the anthropomorphic image. There were no discernable differences in social judgment between participants who were told they were interacting with a human as compared to those told they were interacting with a computer agent, consistent with findings from previous reports. Neither anthropomorphism nor agency influenced reported levels of uncertainty. Implications of these results for those designing and using virtual environments are discussed.},
	author = {Kristine L Nowak},
	doi = {10.1111/j.1083-6101.2004.tb00284.x},
	issn = {1083-6101},
	issue = {2},
	journal = {Journal of Computer-Mediated Communication},
	month = {1},
	title = {The Influence of Anthropomorphism and Agency on Social Judgment in Virtual Environments},
	volume = {9},
	url = {https://doi.org/10.1111/j.1083-6101.2004.tb00284.x},
	year = {2004},
}
@report{Sudweeks1998,
	author = {Fay Sudweeks},
	title = {Interactivity on the Nets},
	url = {https://www.researchgate.net/publication/228587808},
	year = {1998},
}
@report{Koda1996,
	author = {Tomoko Koda and B A In},
	title = {All Rights Reserved Signature of Author Proram in Media Arts and Sciences},
	year = {1996},
}
@report{Wexelblat1998,
	abstract = {A study was performed, comparing two identical systems, which were equipped with different interfaces. One was a conventional data interaction, written in "standard" terse neutral English. The other was an anthropomorphized, conversational style interface. Users performed a set of tasks and gave feedback on the effect and affect of the systems. Our hypotheses were (1) that the affective measures would be improved in the conversational situation but (2) the standard interface would score higher on effective measures. The first hypothesis was weakly supported by the results; however, there was no support for the second hypothesis.},
	author = {Alan Wexelblat},
	title = {Don't Make That Face: a report on anthropomorphizing an interface},
	url = {www.aaai.org},
	year = {1998},
}
@inproceedings{F√∏lstad2018,
	abstract = {Chatbots are increasingly offered as an alternative source of customer service. For users to take up chatbots for this purpose, it is important that users trust chatbots to provide the required support. However, there is currently a lack in knowledge regarding the factors that affect users‚Äô trust in chatbots. We present an interview study addressing this knowledge gap. Thirteen users of chatbots for customer service were interviewed regarding their experience with the chatbots and factors affecting their trust in these. Users‚Äô trust in chatbots for customer service was found to be affected (a) by factors concerning the specific chatbot, specifically the quality of its interpretation of requests and advise, its human-likeness, its self-presentation, and its professional appearance, but also (b) by factors concerning the service context, specifically the brand of the chatbot host, the perceived security and privacy in the chatbot, as well as general risk perceptions concerning the topic of the request. Implications for the design and development of chatbots and directions for future work are suggested.},
	author = {Asbj√∏rn F√∏lstad and Cecilie Bertinussen Nordheim and Cato Alexander Bj√∏rkli},
	doi = {10.1007/978-3-030-01437-7_16},
	isbn = {9783030014360},
	issn = {16113349},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	keywords = {Chatbots,Customer service,Interview study,Trust},
	pages = {194-208},
	publisher = {Springer Verlag},
	title = {What makes users trust a chatbot for customer service? An exploratory interview study},
	volume = {11193 LNCS},
	year = {2018},
}
@article{Nordheim2019,
	abstract = {Chatbots are predicted to play a key role in customer service. Users' trust in such chatbots is critical for their uptake. However, there is a lack of knowledge concerning users' trust in chatbots. To bridge this knowledge gap, we present a questionnaire study (N = 154) that investigated factors of relevance for trust in customer service chatbots. The study included two parts: an explanatory investigation of the relative importance of factors known to predict trust from the general literature on interactive systems and an exploratory identification of other factors of particular relevance for trust in chatbots. The participants were recruited as part of their dialogue with one of four chatbots for customer service. Based on the findings, we propose an initial model of trust in chatbots for customer service, including chatbot-related factors (perceived expertise and responsiveness), environment-related factors (risk and brand perceptions) and user-related factors (propensity to trust technology). RESEARCH HIGHLIGHTS: We extend the current knowledge base on natural language interfaces by investigating factors affecting users' trust in chatbots for customer service. Chatbot-related factors, specifically perceived expertise and responsiveness, are found particularly important to users' trust in such chatbots, but also environment-related factors such as brand perception and user-related factors such as propensity to trust technology. On the basis of the findings, we propose an initial model of users' trust chatbots for customer service.},
	author = {Cecilie Bertinussen Nordheim and Asbj√∏rn F√∏lstad and Cato Alexander Bj√∏rkli},
	doi = {10.1093/iwc/iwz022},
	issn = {09535438},
	issue = {3},
	journal = {Interacting with Computers},
	keywords = {HCI theory, concepts and models, trust,natural language interfaces,user studies},
	month = {5},
	pages = {317-335},
	publisher = {Oxford University Press},
	title = {An Initial Model of Trust in Chatbots for Customer Service - Findings from a Questionnaire Study},
	volume = {31},
	year = {2019},
}